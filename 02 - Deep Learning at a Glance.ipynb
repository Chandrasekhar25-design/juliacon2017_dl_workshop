{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning at a Glance #\n",
    "\n",
    "*Recent advances and challenges.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mark 1 Perceptron ##\n",
    "\n",
    "![The Mark 1 Perceptron](img/perceptron_mark_1.jpg)\n",
    "\n",
    "[Source](http://csis.pace.edu/~ctappert/srd2011/rosenblatt-contributions.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural ups and downs ##\n",
    "\n",
    "A very rought sketch:\n",
    "* 50s/60s: Biologically inspired computation, the perceptron\n",
    "* 70s: Decline after \"Perceptrons\" (1969)\n",
    "* 80s: Connectionism and backpropagation\n",
    "* 90s: Convolutional networks, but limited depth\n",
    "* 00s: Margin-based model dominance\n",
    "* 10s: Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betting on trends ##\n",
    "\n",
    "![The famous Machine Learning bets of 1995](img/ml_bet.jpg)\n",
    "\n",
    "[Source](https://plus.google.com/+YannLeCunPhD/posts/CR18UPiemYB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent Successes #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network ##\n",
    "\n",
    "![Convolutional Neural Network](img/typical_cnn.png)\n",
    "\n",
    "[Source: Wikipedia](https://en.wikipedia.org/wiki/File:Typical_cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Reinforcement Learning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V1eYniJ0Rnk\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "HTML{String}(\"<iframe width=\\\"560\\\" height=\\\"315\\\" src=\\\"https://www.youtube.com/embed/V1eYniJ0Rnk\\\" frameborder=\\\"0\\\" allowfullscreen></iframe>\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thank you @shashi for the hack!\n",
    "HTML(\"\"\"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V1eYniJ0Rnk\" frameborder=\"0\" allowfullscreen></iframe>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source: Two Minute Papers](https://www.youtube.com/watch?v=V1eYniJ0Rnk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaGo ##\n",
    "\n",
    "![AlphaGo in the news](img/alphago_bbc.png)\n",
    "\n",
    "[Source: BBC](http://www.bbc.co.uk/news/technology-35785875)\n",
    "\n",
    "![AlphaGo reasoning about a move](img/alphago_paper_fig_5.png)\n",
    "\n",
    "[Source: Silver et al. (2016)](https://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)\n",
    "\n",
    "[Teaches humans new ways to play the game](https://deepmind.com/blog/innovations-alphago/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaveNet ##\n",
    "\n",
    "![Dilated layers from the WaveNet paper](img/wavenet_fig_3.png)\n",
    "\n",
    "[Source: van den Oord et al. (2016)](https://arxiv.org/abs/1609.03499)\n",
    "\n",
    "*Parametric*\n",
    "<audio src=\"res/wavenet_parametric-1.wav\" controls=\"controls\">\n",
    "    Your browser does not support HTML5 audio.\n",
    "</audio>\n",
    "<audio src=\"res/wavenet_parametric-2.wav\" controls=\"controls\">\n",
    "    Your browser does not support HTML5 audio.\n",
    "</audio>\n",
    "\n",
    "*Concatenative*\n",
    "<audio src=\"res/wavenet_concatenative-1.wav\" controls=\"controls\">\n",
    "    Your browser does not support HTML5 audio.\n",
    "</audio>\n",
    "<audio src=\"res/wavenet_concatenative-2.wav\" controls=\"controls\">\n",
    "    Your browser does not support HTML5 audio.\n",
    "</audio>\n",
    "\n",
    "*WaveNet*\n",
    "<audio src=\"res/wavenet_wavenet-1.wav\" controls=\"controls\">\n",
    "    Your browser does not support HTML5 audio.\n",
    "</audio>\n",
    "<audio src=\"res/wavenet_wavenet-2.wav\" controls=\"controls\">\n",
    "    Your browser does not support HTML5 audio.\n",
    "</audio>\n",
    "\n",
    "[Source](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Style ##\n",
    "\n",
    "![Neural styles applied to an image](img/neural_style_fig_2.png)\n",
    "\n",
    "[Source: Gatys et al. (2015)](https://arxiv.org/abs/1508.06576)\n",
    "\n",
    "![Neural style filters](img/neural_style_fig_1.png)\n",
    "\n",
    "[Source: Gatys et al. (2015)](https://arxiv.org/abs/1508.06576)\n",
    "\n",
    "[Open Source implementation](https://github.com/jcjohnson/neural-style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Representations ##\n",
    "\n",
    "![Word representations](img/word_representations.svg)\n",
    "\n",
    "![Word representations](img/word_representations_zoom.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network ##\n",
    "\n",
    "![Encoder Decoder](img/rnn_encode_decode.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent !Successes #\n",
    "\n",
    "[![Google Traslate having issues](img/mordor_bbc.png)](http://www.bbc.co.uk/news/technology-35251478)\n",
    "\n",
    "Source: [BBC](http://www.bbc.co.uk/news/technology-35251478)\n",
    "\n",
    "[![Tay having personality issues](img/tay_bbc.png)](http://www.bbc.co.uk/news/technology-35902104)\n",
    "\n",
    "Source: [BBC](http://www.bbc.co.uk/news/technology-35902104)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is this happening now? ##\n",
    "\n",
    "* Theoretical breakthroughs\n",
    "* Computational power\n",
    "* Data availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do we go from here? ##\n",
    "\n",
    "My biases:\n",
    "\n",
    "* Multi-task learning\n",
    "* Reinforcement learning\n",
    "* Explainable model\n",
    "* Hybrid models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware (I think this is up to date) ##\n",
    "\n",
    "Advice:\n",
    "\n",
    "* Best GPU overall (by a small margin): Titan Xp\n",
    "* Cost efficient but expensive: GTX 1080 Ti, GTX 1070, GTX 1080\n",
    "* Cost efficient and cheap:  GTX 1060 (6GB)\n",
    "* I work with data sets > 250GB: GTX Titan X (Maxwell), NVIDIA Titan X Pascal, or NVIDIA Titan Xp\n",
    "* I have little money: GTX 1060 (6GB)\n",
    "* I have almost no money: GTX 1050 Ti (4GB)\n",
    "* I am a researcher: GTX 1080 Ti. In some cases, like natural language processing, a GTX 1070 or GTX 1080 might also be a solid choice â€” check the memory requirements of your current models\n",
    "* I started deep learning and I am serious about it: Start with a GTX 1060 (6GB). Depending of what area you choose next (startup, Kaggle, research, applied deep learning) sell your GTX 1060 and buy something more appropriate\n",
    "* I want to try deep learning, but I am not serious about it: GTX 1050 Ti (4 or 2GB)\n",
    "\n",
    "[Source](http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework ##\n",
    "\n",
    "* [TensorFlow.jl](https://github.com/malmaud/TensorFlow.jl)\n",
    "* [MXNet.jl](https://github.com/dmlc/MXNet.jl)\n",
    "* [Knet.jl](https://github.com/denizyuret/Knet.jl)\n",
    "* [Mocha.jl](https://github.com/pluskid/Mocha.jl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Talks ##\n",
    "\n",
    "* [\"Deep Learning with Julia\"](https://juliacon2017.sched.com/event/At1u/deep-learning-with-julia) with Mike Innes, Jonathan Malmaud, and Pontus Stenetorp\n",
    "* [\"Flux: Machine Learning with Julia\"](https://juliacon2017.sched.com/event/At4F/flux-machine-learning-with-julia) with Mike Innes\n",
    "* [\"Knet.jl: Beginning Deep Learning with 100 Lines of Julia\"](https://juliacon2017.sched.com/event/At3z/knetjl-beginning-deep-learning-with-100-lines-of-julia) with Deniz Yuret\n",
    "* [\"Modern Machine Learning in Julia with TensorFlow.jl\"](https://juliacon2017.sched.com/event/At4E/modern-machine-learning-in-julia-with-tensorflowjl) with Jonathan Malmaud\n",
    "* [\"GPU Programming with Julia\"](https://juliacon2017.sched.com/event/At2U/gpu-programming-with-julia) with Tim Besard, Valentin Churavy, and Simon Danisch\n",
    "* [\"Programming NVIDIA GPUs in Julia with CUDAnative.jl\"](https://juliacon2017.sched.com/event/At4K/programming-nvidia-gpus-in-julia-with-cudanativejl) with Tim Besard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0-rc2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
